# 데이터 분석



## 치킨집

### 데이터 가공 및 트리 맵 표현

- 소재지 전체 주소 가공

  ```
  library("readxl")
  
  ck<-read_excel("치킨집_가공.xlsx")
  head(ck)
  
  addr<-substr(ck$소재지전체주소,11,16)
  head(addr)
  
  addr_num<-gsub("[0-9]","",addr) #숫자제거
  addr_trim <- gsub(" ", "",addr_num) #공백제거
  head(addr_trim)
  ```

- 동별 업소 개수 확인

  ```
  library(dplyr)
  
  addr_count<-addr_trim %>% table() %>% data.frame()
  #도수 분포표 작성 후 데이터 프레임으로 변환
  head(addr_count)
  ```

- 트리맵으로 표현

  ```
  library(treemap)
  treemap(addr_count,index=".",vSize="Freq",title="서대문구 동별 치킨집  분포")
  
  arrange(addr_count,desc(Freq)) %>% head() #내림차순 정렬
  ```



## 미세먼지

### 상자 그림으로 시각화 & t 검정

- 원시 데이터 가져오기

  ```
  library(readxl)
  dustdata<-read_excel("dustdata.xlsx")
  
  View(dustdata)
  str(dustdata)
  ```

- 비교할 지역 데이터만 추출하기

  ```
  library(dplyr)
  dustdata_anal <- dustdata %>% filter(area %in% c("성북구","중구")) #성북구와 중구 데이터만 추출
  View(dustdata_anal)
  ```

- 데이터 현황 파악

  - 날짜, 지역 데이터 포함 여부

    ````
    count(dustdata_anal, yyyymmdd) %>% arrange(desc(n)) #yyyymmdd에 따른 데이터 수 파악
    count(dustdata_anal,area) %>% arrange(desc(n)) #area에 따른 데이터 수 파악
    ````

  - 성북구와 중구의 데이터 분리

  ```
  dust_anal_area_sb<-subset(dustdata_anal,area=="성북구")
  dust_anal_area_jg<-subset(dustdata_anal,area=="중구")
  dust_anal_area_sb
  dust_anal_area_jg
  ```

  `describe()`: 기초 통계량을 한 번에 확인 가능(psych 패키지)

```
library(psych)
describe(dust_anal_area_sb$finedust) #성북구 미세먼지량에 대한 기초 통계랑 도출
describe(dust_anal_area_jg$finedust)
```

- 분포 확인 및 가설 검정

  ```
  boxplot(dust_anal_area_sb$finedust, dust_anal_area_jg$finedust,
          main="finedust_compare",xlab="AREA",names=c("성북구","중구"),
          ylab ="FINEDUST_PM",col=c("blue","green"))
          
  t.test(data=dustdata_anal,finedust~area,var.equal=T)
  ```

  - dustdata_anal 데이터 세트에서 측정소명(area)에 따라 미세먼지 농도 평균에 대한 차이를 검증



## 트위터

### 키워드 검색 & 워드클라우드 표현

- twitter 패키지 설치 & OAuth인증

  ```
  library(twitteR)
  
  api_key <- "gjUkHgO8bFmNobRk4g0Jas8xb"
  api_secret <- "loF0mtnzLhtQDFjahdRHox6wcR1fiD6Fw95DP5QCSy3rLTTP1K"
  access_token <- "607145164-8L5HtzopZzhjuBCgusUGKE3MHOa9P4RbmhUrM0E1"
  access_token_secret <- "2wn2bsCA7JIH5DZ5Ss1deS5BNLabzaX2xSpM2ZLMIqwQf"
  ```

  - `setup_twitter_oauth()`:  키 값으로 OAuth 인증

    ```
    setup_twitter_oauth(api_key,api_secret, access_token,access_token_secret)
    ```

- 키워드 검색 및 결과 값 가져오기

  - `searchTwitter()` : 키워드 검색

  ```
  key <- "선거"
  key <- enc2utf8(key)
  result <- searchTwitter(key, n=100, lang='ko')
  ```

  - `twLIstToDF()` : 리스트에서 트윗의 텍스트만 분리 (-> 데이터 프레임 형태)

    ```
    DF <- twListToDF(result)
    ```

- 텍스트에서 명사만 추출

  ```
  library(KoNLP)
  useSejongDic()
  
  content_noun <- sapply(content,extractNoun,USE.NAMES=F) #명사추출
  content_noun <- unlist(content_noun) #벡터로 변환
  
  content_noun <- Filter(function(x){nchar(x)>=2},content_noun)
  contnet_noun <- gsub("[A-Za-z0-9]","",content_noun) #영어, 숫자 제거
  contnet_noun <- gsub("[~!@#$%^&*()-_|+=?:]","",content_noun) 
  contnet_noun <- gsub("[ㄱ-ㅎ]","",content_noun) 
  contnet_noun <- gsub("(ㅜ|ㅠ)+","",content_noun) 
  
  word_table <- table(content_noun)
  ```

- 워드클라우드

  ```
  library(wordcloud2)
  wordcloud2(word_table,fontFamily="맑은 고딕",size=5,color="random-light",
             backgroundColor="black")
  ```





## 텍스트 마이닝

비정형 텍스트 구조화된 데이터 의미있는 정보 추출 연관성분석

### 자연어 처리

형태소분석기, 구문분석기와 같은 사람이 작성핚 글이나 대화를 컴퓨터를 통해 해석핛 수 있게 하는 소프트웨어를 개발하거나 연구하고 그런 것들을 이용해서 실제로 작업하는 것

- 종류

  - KoNLP

  - 한나눔

  - twListToDF

    

### tm 패키지

- 패키지 설치 및 데이터 설정

  ```
  library(tm)
  
  lunch <- c("커피 파스타 치킨 샐러드 아이스크림",
             "커피 우동 소고기김밥 귤",
             "참치김밥 커피 오뎅",
             "샐러드 피자 파스타 콜라",
             "티라무슈 햄버거 콜라",
             "파스타 샐러드 커피"
  )
  ```

- 벡터값 변환

  `VCorpus`

  `TermDocumentMatrix`

  ```
  cps <- VCorpus(VectorSource(lunch))
  tdm <- TermDocumentMatrix(cps, 
                            control=list(wordLengths = c(1, Inf)))
  #글자수 2이하인 행도 추출
  tdm
  (m <- as.matrix(tdm))
  ```

- 동시 출현한 텍스트 단위로 나타내기

  ```
  com <- m %*% t(m)
  ```

​               Docs
Terms    1 2 3 4 5 6
  귤     0 0 0 0 0 1
  망고   1 0 0 0 1 0
  바나나 0 0 0 1 1 0
  복숭아 0 0 1 1 0 0
  사과   1 0 1 0 0 0
  오렌지 0 0 0 1 0 1
  자두   0 1 0 0 0 0
  자몽   0 1 0 0 0 0
  포도   1 1 1 0 1 1